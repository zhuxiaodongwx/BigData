# Flume多路复用
# 读取一个日志，根据event中header的key-value，分类发送给两个agent

a1.sources = r1
a1.channels = c1 c2
a1.sinks = k1 k2

# Describe/configure the source
a1.sources.r1.type = TAILDIR
a1.sources.r1.positionFile = /opt/module/flume/jobs/tail_dir.json
a1.sources.r1.filegroups = f1
a1.sources.r1.filegroups.f1 = /opt/module/flume/datas/xiaodong.log

# 配置channel selector 多路复用
a1.sources.r1.selector.type = multiplexing
# event中header中的key是state
a1.sources.r1.selector.header = mark
# event中header的key是“state”，如果值是“toc1”，发送到c1
a1.sources.r1.selector.mapping.toc1 = c1
# event不满足以上映射条件的，默认发送到c2 channel
a1.sources.r1.selector.default = c2

# 自定义拦截器
a1.sources.r1.interceptors = i1
a1.sources.r1.interceptors.i1.type = static
# 在event中添加一个header，key是“mark”，value是“toc1”
a1.sources.r1.interceptors.i1.key = mark
a1.sources.r1.interceptors.i1.value = toc2

# Use a channel which buffers events in memory
a1.channels.c1.type = memory
a1.channels.c1.capacity = 1000
a1.channels.c1.transactionCapacity = 100

a1.channels.c2.type = memory
a1.channels.c2.capacity = 1000
a1.channels.c2.transactionCapacity = 100

# Describe the sink
a1.sinks.k1.type = avro
a1.sinks.k1.hostname = hadoop102
a1.sinks.k1.port = 4444

a1.sinks.k2.type = avro
a1.sinks.k2.hostname = hadoop102
a1.sinks.k2.port = 6666

# Bind the source and sink to the channel
# 一个source对接两个channel
a1.sources.r1.channels = c1 c2
a1.sinks.k1.channel = c1
a1.sinks.k2.channel = c2
